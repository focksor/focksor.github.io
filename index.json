[{"categories":[],"content":"概述 本文将探索 Linux 下不同内存统计方法的差异，以及描述相应方法的适用场景。 你可能想要知道 top, ps, systemctl status, smem 等工具或命令显示的内存用量分别有什么含义，其显示的数字又为什么各有差异，本文将进行深入分析，带你了解其中的奥妙，并让你清楚应该在什么场景下应该使用哪个指标。 ","date":"2025-06-18","objectID":"/posts/linux-%E5%86%85%E5%AD%98%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90/:1:0","tags":["Programming"],"title":"Linux 内存统计方法差异分析","uri":"/posts/linux-%E5%86%85%E5%AD%98%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90/"},{"categories":[],"content":"背景 笔者在分析 Linux 机器上的内存使用情况时，发现一个奇怪的现象：systemctl 和 ps 的内存（RSS）数据对不上，两者有时候会无法形成逻辑上的关联关系。 例如，在分析 Nginx 应用的内存使用情况时，笔者观察到了如下的数据： # uname -a Linux firewall 5.10.204-g39484bf51955 #1 SMP Tue Jun 10 01:12:29 CST 2025 x86_64 GNU/Linux # systemctl status nginx ● nginx.service - A high performance web server and a reverse proxy server Loaded: loaded (/usr/lib/systemd/system/nginx.service; enabled; vendor preset: enabled) Active: active (running) since Tue 2025-06-10 09:11:03 CST; 2h 31min ago Process: 3954 ExecReload=/usr/sbin/nginx -g daemon on; master_process on; -s reload (code=exited, status=0/SUCCESS) Main PID: 665 (nginx) Tasks: 3 (limit: 5617) Memory: 9.9M CGroup: /system.slice/nginx.service ├─ 665 nginx: master process /usr/sbin/nginx -g daemon on; master_process on; └─3958 nginx: worker process # ps aux | head -1 \u0026\u0026 ps aux | grep nginx USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 665 0.0 0.0 113068 8820 ? Ss 09:11 0:00 nginx: master process /usr/sbin/nginx -g daemon on; master_process on; www-data 3958 0.0 0.0 182940 12832 ? Sl 09:12 0:00 nginx: worker process 如上我们可以从 systemctl status nginx 中看到，nginx 启动了，分别是一个 master 和一个 worker，两者的内存一共占用了 9.9M。而当我们使用 ps 指令去查看时，发现两个进程的 RSS 内存使用量分别是 8820 和 12832，即总共用了 8820+12832=21652kB=21.14MB。明显大于 systemctl status 显示的内存用量。 那有人就要说了，nginx 的 worker 很明显是从 master 中 fork 出来的，所以两个进程的内存有一部分是共享的（shared and COW），所以会比两个进程单独显示的用量总数大，很合理吧？ 一开始笔者也是这么认为的，然而随后便发现这个说法经不起推敲：worker 的总内存用量 12832=12.5MB，大于 systemctl status 中显示的内存总量 9.9M。就算 worker 共享了 master 的全部内存，那也不能比总量大吧？ 暂时没想明白这是怎么算出来的，笔者随后又去看了另一台机器（nginx 配置相同但机器硬件和系统不同），结果看到了更离谱的数据： # uname -a Linux firewall 4.14.76-gd85b09009 #1 SMP PREEMPT Wed May 28 16:22:58 CST 2025 aarch64 GNU/Linux # systemctl status nginx ● nginx.service - A high performance web server and a reverse proxy server Loaded: loaded (/usr/lib/systemd/system/nginx.service; enabled; vendor preset: enabled) Active: active (running) (thawing) since Mon 2025-06-09 16:14:51 CST; 19h ago Main PID: 7401 (nginx) Tasks: 3 (limit: 4629) Memory: 26.5M CGroup: /system.slice/nginx.service ├─7401 nginx: master process /usr/sbin/nginx -g daemon on; master_process on; └─7403 nginx: worker process # ps aux | head -1 \u0026\u0026 ps aux | grep nginx USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 7401 0.0 0.0 43328 2056 ? Ss Jun09 0:00 nginx: master process /usr/sbin/nginx -g daemon on; master_process on; www-data 7403 0.0 0.2 121796 11524 ? Sl Jun09 0:15 nginx: worker process 可以看到，同样是 nginx，其 master 和 worker 的 RSS 内存占用分别是 2056 和 11524，总量是 2056+11524=13580kB=13.26MB，甚至比 systemctl status nginx 上显示的 26.5M 更小？ 作为一个严谨的程序员，笔者想要找出其背后的原理，通过统一的理论同时解释上面两组数据——更重要的是，让我可以知道究竟哪个数据才能真实地表达对应应用程序的内存情况。 ","date":"2025-06-18","objectID":"/posts/linux-%E5%86%85%E5%AD%98%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90/:2:0","tags":["Programming"],"title":"Linux 内存统计方法差异分析","uri":"/posts/linux-%E5%86%85%E5%AD%98%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90/"},{"categories":[],"content":"理论分析 [!info] 本文档分析过程基于 Linux kernel 4.14 版本 ","date":"2025-06-18","objectID":"/posts/linux-%E5%86%85%E5%AD%98%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90/:3:0","tags":["Programming"],"title":"Linux 内存统计方法差异分析","uri":"/posts/linux-%E5%86%85%E5%AD%98%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90/"},{"categories":[],"content":"命令数据来源 ps RSS 数据来源 阅读 源码，不难看出 ps 指令的 RSS 内存用量直接读取自 /proc/\u003cpid\u003e/status 中的 VmRSS 字段。如下也可以看到两个数据是完全一样的： # ps aux | head -1 \u0026\u0026 ps aux | grep nginx USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 129137 0.0 0.0 43312 2340 ? Ss Jun11 0:00 nginx: master process /usr/sbin/nginx -g daemon on; master_process on; www-data 129139 0.0 0.3 121700 12148 ? Sl Jun11 0:13 nginx: worker process # cat /proc/129137/status | grep VmRSS VmRSS: 2340 kB # cat /proc/129139/status | grep VmRSS VmRSS: 12148 kB [!note] 源码定位：main() -\u003e simple_spew -\u003e show_one_proc -\u003e format_array -\u003e pr_rss -\u003e status2proc top RSS 数据来源 阅读 源码，不难发现 top 指令的 RES 内存用量取自 /proc/\u003cpid\u003e/statm 并乘以每页大小。如下也可以看到两个数据是完全一样的： # top -p 129137 -p 129139 PID USER PR NI VIRT RES %CPU %MEM TIME+ S COMMAND 129137 root 20 0 43312 2340 0.0 0.1 0:00.00 S nginx: master process /usr/sbin/nginx -g daemon on; master_process on; 129139 www-data 20 0 121700 12148 0.0 0.3 0:13.42 S `- nginx: worker process # awk '{print $2*4}' /proc/129137/statm 2340 # awk '{print $2*4}' /proc/129139/statm 12148 [!note] 源码定位：main() -\u003e frame_make -\u003e window_show -\u003e task_show -\u003e statm2proc smem RSS 数据来源 阅读 源码，可以看到 smem 指令的 RSS 内存用量取自 /proc/\u003cpid\u003e/smaps，是一个进程所有已映射内存区域的 RSS 总和（即也是 /proc/\u003cpid\u003e/smaps_rollup 中 Rss 字段的值）。如下也可以看到几个数据是完全一样的： # smem -P nginx PID User Command Swap USS PSS RSS 129137 root nginx: master process /usr/ 4 480 1175 3144 129139 www-data nginx: worker process 4 6540 7537 12352 # awk '/^Rss:/ {rss += $2} END {print rss \" kB\"}' /proc/129137/smaps 3144 kB # grep Rss /proc/129137/smaps_rollup Rss: 3144 kB # awk '/^Rss:/ {rss += $2} END {print rss \" kB\"}' /proc/129139/smaps 12352 kB # grep Rss /proc/129139/smaps_rollup Rss: 12352 kB [!note] 源码定位： showpids -\u003e processtotals -\u003e pidtotals -\u003e pidmaps systemctl status RSS 数据来源 阅读 源码，可以看到 systemctl status 的 Memory 数据用量取自 /sys/fs/cgroup/memory/\u003cunit.path\u003e/memory.usage_in_bytes (cgroup v1)或 /sys/fs/cgroup/memory/\u003cunit.path\u003e/memory.current（cgroup v2） 。如下也可以看到两个数据是完全一样的： # systemctl show nginx -p MemoryCurrent MemoryCurrent=10371072 # cat /sys/fs/cgroup/memory/system.slice/nginx.service/memory.usage_in_bytes 10371072 # awk '{printf \"%.2f MiB\\n\", $1/1024/1024}' /sys/fs/cgroup/memory/system.slice/nginx.service/memory.usage_in_bytes 9.89 MiB # systemctl status nginx ● nginx.service - A high performance web server and a reverse proxy server Loaded: loaded (/usr/lib/systemd/system/nginx.service; enabled; vendor preset: enabled) Active: active (running) (thawing) since Wed 2025-06-11 17:39:02 CST; 4 days ago Main PID: 129137 (nginx) Tasks: 3 (limit: 4629) Memory: 9.8M CGroup: /system.slice/nginx.service ├─129137 nginx: master process /usr/sbin/nginx -g daemon on; master_process on; └─129139 nginx: worker process [!note] 源码定位：print_status_info -\u003e status_map -\u003e bus_unit_cgroup_vtable -\u003e property_get_current_memory -\u003e unit_get_memory_current -\u003ecg_get_attribute_as_uint64 ","date":"2025-06-18","objectID":"/posts/linux-%E5%86%85%E5%AD%98%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90/:3:1","tags":["Programming"],"title":"Linux 内存统计方法差异分析","uri":"/posts/linux-%E5%86%85%E5%AD%98%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90/"},{"categories":[],"content":"内核数据来源 在上个小节对各命令的数据来源分析中，我们可以看到每个命令的数据其实是来源于不同的文件，而这些文件是由 Linux 内核创建的虚拟文件，反映了程序的运行状态。下面是这些文件相应字段的定义： 文件 字段 使用文件数据的命令 说明 /proc/\u003cpid\u003e/status VmRSS top size of memory portions. It contains the three following parts (VmRSS = RssAnon + RssFile + RssShmem) /proc/\u003cpid\u003e/statm resident ps (same as VmRSS in status) /proc/\u003cpid\u003e/smaps_rollup Rss smem it contains these fields:- Pss_Anon- Pss_File- Pss_Shmem /sys/fs/cgroup/memory/\\\u003cunit.path\u003e/memory.usage_in_bytes NA systemctl status 5.5 usage_in_bytesFor efficiency, as other kernel components, memory cgroup uses some optimization to avoid unnecessary cacheline false sharing. usage_in_bytes is affected by the method and doesn’t show ‘exact’ value of memory (and swap) usage, it’s a fuzz value for efficient access. (Of course, when necessary, it’s synchronized.) If you want to know more exact memory usage, you should use RSS+CACHE(+SWAP) value in memory.stat(see 5.2). 注意到 procfs 的 status 和 statm 完全一致，包含了一个进程中所有 匿名+文件映射+共享内存映射 内存。 而 smaps_rollup 也是同样的定义，按理来说其数值与上面的值一模一样，但是由于统计方法的差异（status/statm 使用计数器进行统计，smaps 的值是遍历 VMZ 计算来的，所以会更精确），smaps_rollup 的值一般会稍大于 status/statm，但是差异不会很大。 [!quote] /proc/pid/statm - memory usage information Some of these values are inaccurate because of a kernel- internal scalability optimization. If accurate values are required, use /proc/pid/smaps or /proc/pid/smaps_rollup instead, which are much slower but provide accurate, detailed information. 而对于 cgroupfs，其中的 memory.usage_in_bytes 约等于 memory.stat 中的 RSS+CACHE。 但是 cgroup 的计数方法与 procfs 中的不一样，其采用的是“首次接触时计费法”，即谁先映射一块共享地址，这块地址的内存开销就算在谁头上。因此，cgroup 的内存统计数据有时候会与实际不同，更多会与服务启动顺序相关（例如，一个服务启动得早，相关动态库的开销就算它上面了，而让其它服务使用相关动态库的服务先启动会降低该服务显示的内存使用量）。 [!quote] 2.3 Shared Page Accounting Shared pages are accounted on the basis of the first touch approach. The cgroup that first touches a page is accounted for the page. The principle behind this approach is that a cgroup that aggressively uses a shared page will eventually get charged for it (once it is uncharged from the cgroup that brought it in – this will happen on memory pressure). ","date":"2025-06-18","objectID":"/posts/linux-%E5%86%85%E5%AD%98%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90/:3:2","tags":["Programming"],"title":"Linux 内存统计方法差异分析","uri":"/posts/linux-%E5%86%85%E5%AD%98%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90/"},{"categories":[],"content":"实践分析 回到开头的例子，当一个 systemd 服务包含多个进程的时候，为什么有时候 service memory 数值比所有进程的 ps RSS 加起来多，而有时候比单个进程 ps RSS 还要少呢？让我们分情况进行讨论。 ","date":"2025-06-18","objectID":"/posts/linux-%E5%86%85%E5%AD%98%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90/:4:0","tags":["Programming"],"title":"Linux 内存统计方法差异分析","uri":"/posts/linux-%E5%86%85%E5%AD%98%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90/"},{"categories":[],"content":"systemctl status 小于 ps/top 当 systemctl status 显示的 Memory 量比其所有子进程通过 ps/top 命令看到的 RSS 量加起来更少，这是很正常的，也是最常见的。 这主要是因为 systemctl 对于共享内存空间（如多进程共享的动态库）等的统计规则是“首次接触时计费”，而 ps/top 的 RSS 统计量是会在每个进程中都计入共享的内存空间。 如下案例，可以看到 systemctl status 的内存用量小于该服务内个进程 RSS 用量的总和： # systemctl status nginx ● nginx.service - A high performance web server and a reverse proxy server Loaded: loaded (/usr/lib/systemd/system/nginx.service; enabled; vendor preset: enabled) Active: active (running) (thawing) since Wed 2025-06-11 17:39:02 CST; 6 days ago Main PID: 129137 (nginx) Tasks: 3 (limit: 4629) Memory: 9.9M CGroup: /system.slice/nginx.service ├─129137 nginx: master process /usr/sbin/nginx -g daemon on; master_process on; └─129139 nginx: worker process # ps aux | head -1 \u0026\u0026 ps aux | grep nginx USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 129137 0.0 0.0 43312 2340 ? Ss Jun11 0:00 nginx: master process /usr/sbin/nginx -g daemon on; master_process on; www-data 129139 0.0 0.3 121700 12152 ? Sl Jun11 0:15 nginx: worker process ","date":"2025-06-18","objectID":"/posts/linux-%E5%86%85%E5%AD%98%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90/:4:1","tags":["Programming"],"title":"Linux 内存统计方法差异分析","uri":"/posts/linux-%E5%86%85%E5%AD%98%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90/"},{"categories":[],"content":"systemctl status 大于 ps/top 当 systemctl status 显示的 Memory 量比其所有进程通过 ps/top 命令看到的 RSS 量加起来更多时，这种情况也是很正常的。 上文中我们提到，systemctl status 的数据源于 cgroup 中的 memory.usage_in_bytes，而该文件的用量近似于 memory.stat 中的 RSS+CACHE。这里的 cache 除了常规的共享空间外，还包含了内核为该 cgroup 缓存的文件数据大小，属于内存中的页缓存部分。这部分缓存是操作系统为了提高文件 I/O 性能而保留的，缓存内容是文件的磁盘内容副本。 如下案例，我们可以看到 systemctl status 的内存用量远大于该服务内个进程 RSS 用量的总和： # systemctl status nginx ● nginx.service - A high performance web server and a reverse proxy server Loaded: loaded (/usr/lib/systemd/system/nginx.service; enabled; vendor preset: enabled) Active: active (running) (thawing) since Sat 2025-05-24 02:36:41 CST; 3 weeks 3 days ago Process: 2083 ExecReload=/usr/sbin/nginx -g daemon on; master_process on; -s reload (code=exited, status=0/SUCCESS) Main PID: 685 (nginx) Tasks: 3 (limit: 4629) Memory: 31.6M CGroup: /system.slice/nginx.service ├─ 685 nginx: master process /usr/sbin/nginx -g daemon on; master_process on; └─2107 nginx: worker process # ps aux | head -1 \u0026\u0026 ps aux | grep nginx USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 685 0.0 0.1 43684 7832 ? Ss May24 0:00 nginx: master process /usr/sbin/nginx -g daemon on; master_process on; www-data 2107 0.0 0.3 121748 12720 ? Sl May24 2:32 nginx: worker process 查看相应的 memory.stat 文件，可以看到其 cache 比例特别高，而 RSS 距离 systemctl status 显示的数据相差甚远： # head -2 /sys/fs/cgroup/memory/system.slice/nginx.service/memory.stat cache 24866816 rss 7581696 # head -2 /sys/fs/cgroup/memory/system.slice/nginx.service/memory.stat | \\ \u003e awk '{ printf \"%s %.2f MiB\\n\", $1, $2 / 1024 / 1024 }' cache 23.71 MiB rss 7.23 MiB 要如何说明这里的 cache 中包含了很多内核缓存的文件数据呢？让我们清理一下缓存试试： # echo 3 \u003e /proc/sys/vm/drop_caches # head -2 /sys/fs/cgroup/memory/system.slice/nginx.service/memory.stat | \\ \u003e awk '{ printf \"%s %.2f MiB\\n\", $1, $2 / 1024 / 1024 }' cache 1.79 MiB rss 7.23 MiB # systemctl status nginx ● nginx.service - A high performance web server and a reverse proxy server Loaded: loaded (/usr/lib/systemd/system/nginx.service; enabled; vendor preset: enabled) Active: active (running) (thawing) since Sat 2025-05-24 02:36:41 CST; 3 weeks 3 days ago Process: 2083 ExecReload=/usr/sbin/nginx -g daemon on; master_process on; -s reload (code=exited, status=0/SUCCESS) Main PID: 685 (nginx) Tasks: 3 (limit: 4629) Memory: 9.7M CGroup: /system.slice/nginx.service ├─ 685 nginx: master process /usr/sbin/nginx -g daemon on; master_process on; └─2107 nginx: worker process 可以看到，清理缓存后，cache 一下子少了很多（但是不是全没了，因为还包含共享内存等缓存空间），而 systemctl status 的数据也回到了我们上个案例中的水平，足以验证我们的理论是完全正确的。 ","date":"2025-06-18","objectID":"/posts/linux-%E5%86%85%E5%AD%98%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90/:4:2","tags":["Programming"],"title":"Linux 内存统计方法差异分析","uri":"/posts/linux-%E5%86%85%E5%AD%98%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90/"},{"categories":[],"content":"systemctl status 等于 ps/top 那么可能就有人要问了，systemctl status 可能小于 ps/top 的值，也可能大于 ps/top 的值，那能不能基本等于这个值呢？ 让我们回忆上面的内容，当 systemd service 启动时，所有加载的数据都在私有内存空间（或首次加载的共享内存空间）的话，由于 ps/top 也会计算到这些信息，这个时候两者统计的 RSS 信息就基本一致了。当然也别忘了 cgroup 的 cache 还附加了内核缓存的文件数据大小，这个也要清理一下。 如此操作之后，systemctl status 的值应该就基本等于 ps/top 的值了，由于统计口径的差别，两者可能会有一定的偏差，但理论上来说差异不会太大。 ","date":"2025-06-18","objectID":"/posts/linux-%E5%86%85%E5%AD%98%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90/:4:3","tags":["Programming"],"title":"Linux 内存统计方法差异分析","uri":"/posts/linux-%E5%86%85%E5%AD%98%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90/"},{"categories":[],"content":"总结 在上面的文档中，我们一共分析了这些命令：ps、top、smem、systemctl status。从这些命令的不同实现方法中，我们也可以看到它们的作者在实现时的思考： ps/top 命令数据取自 procfs 中的 statm 和 status，两者数据完全一致，反应了所有映射到一个程序的内存空间的内存总量。 smem 稍微复杂，分了 USS, PSS, RSS 几个指标，其中： USS 表示一个进程独享的内存量，反应了 kill 掉这个进程能释放的空间 PSS 表示一个进程分摊后的负载，是 USS + (共享部分内存空间 / 共享进程数) RSS 与 ps/top 的指标基本相同，仅因为统计口径不同数据稍有偏差 systemctl status 使用了特殊的“首次接触时计费”统计法，而且还包含了内存缓存的文件信息，反应了“启动这个服务消耗的内存”。 因此，这些命令适用的场景不同，我们在分析系统内存占用时，需要根据具体的需求选择合适的工具： 当需要快速了解进程的整体内存映射情况时，如进行系统资源初步评估或排查进程是否异常占用内存，使用 ps 或 top 是最直接的选择，它们开销小、信息全面，但无法细化内存来源或共享程度。 当需要准确评估某个服务或进程对系统内存的真实负担时，推荐使用 smem。特别是在容器化、多进程共享库广泛使用的系统中，smem 提供的 USS/PSS 能够更真实地反映每个进程的“责任内存”，避免因共享库导致的重复计算。 当我们希望从系统服务的角度出发，评估每个 systemd 管理的服务对系统资源的消耗时，systemctl status 提供的“首次接触时计费”是一种更贴近服务视角的内存估算方式。它能够包含服务启动时加载的共享库和缓存文件所带来的额外内存开销，对容量规划和资源分配更有参考意义。 最后需要注意的是，不同命令在统计口径上存在差异，有些数据来源于内核快照，有些来源于动态计算，可能在高负载或频繁变化的场景下出现偏差。因此在分析复杂内存问题时，我们可能需要结合多种工具交叉验证，并深入查看 /proc/\u003cpid\u003e/smaps 等底层接口以获取更精细的数据支持。 ","date":"2025-06-18","objectID":"/posts/linux-%E5%86%85%E5%AD%98%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90/:5:0","tags":["Programming"],"title":"Linux 内存统计方法差异分析","uri":"/posts/linux-%E5%86%85%E5%AD%98%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90/"},{"categories":[],"content":"资源 procps-ng / procps · GitLab systemd/systemd: The systemd System and Service Manager torvalds/linux at v4.14 Memory Resource Controller — The Linux Kernel documentation memory management - Linux OS: /proc/[pid]/smaps vs /proc/[pid]/statm - Stack Overflow ","date":"2025-06-18","objectID":"/posts/linux-%E5%86%85%E5%AD%98%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90/:6:0","tags":["Programming"],"title":"Linux 内存统计方法差异分析","uri":"/posts/linux-%E5%86%85%E5%AD%98%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90/"},{"categories":[],"content":"概述 本文主要讨论 Python 应用如何在 import 一个模块之后 de-import/un-import 此模块。 ","date":"2025-06-13","objectID":"/posts/python-%E5%88%A0%E9%99%A4%E5%B7%B2%E5%AF%BC%E5%85%A5%E7%9A%84%E6%A8%A1%E5%9D%97/:1:0","tags":["Programming"],"title":"Python 删除已导入的模块","uri":"/posts/python-%E5%88%A0%E9%99%A4%E5%B7%B2%E5%AF%BC%E5%85%A5%E7%9A%84%E6%A8%A1%E5%9D%97/"},{"categories":[],"content":"背景 在使用 Python 的过程中，我们很多时候需要 import 一个库来帮助自己完成一些代码逻辑。 然而，import 一个库意味着会引入额外的内存使用，而在一些内存受限的环境（如嵌入式设备上），内存是很珍贵的，如果只是为了一个使用频次很低的功能引入一个库会多少显得有些奢侈。 因此，Python 应用如何在 import 一个库并使用完成后 “de-import” ，在某些时候显得尤为重要。 笔者查阅了互联网上的一些资料，均未能达到释放内存的效果，因此写下了这篇文档。 ","date":"2025-06-13","objectID":"/posts/python-%E5%88%A0%E9%99%A4%E5%B7%B2%E5%AF%BC%E5%85%A5%E7%9A%84%E6%A8%A1%E5%9D%97/:2:0","tags":["Programming"],"title":"Python 删除已导入的模块","uri":"/posts/python-%E5%88%A0%E9%99%A4%E5%B7%B2%E5%AF%BC%E5%85%A5%E7%9A%84%E6%A8%A1%E5%9D%97/"},{"categories":[],"content":"How To ","date":"2025-06-13","objectID":"/posts/python-%E5%88%A0%E9%99%A4%E5%B7%B2%E5%AF%BC%E5%85%A5%E7%9A%84%E6%A8%A1%E5%9D%97/:3:0","tags":["Programming"],"title":"Python 删除已导入的模块","uri":"/posts/python-%E5%88%A0%E9%99%A4%E5%B7%B2%E5%AF%BC%E5%85%A5%E7%9A%84%E6%A8%A1%E5%9D%97/"},{"categories":[],"content":"判断规则 判断一个库是否已释放的最重要标准是引入库前和释放库后的内存用量相差不大，这样才能起到释放内存的作用。如果只是代码中无法使用库及相关接口，但是内存还是贮留在系统中，那意义就不大了。 综上，判断一个库是否已经被释放的步骤如下： 记录此时 Python 应用内存用量为 A 引入一个库 使用该库进行一些操作 释放该库 记录此时 Python 应用内存用量为 B 如果 B 与 A 相差不大，则认为该库已完成释放 为了方便描述，我们在下文中均以导入 asyncio 模块为例（因为它足够大，且不用额外安装）。 ","date":"2025-06-13","objectID":"/posts/python-%E5%88%A0%E9%99%A4%E5%B7%B2%E5%AF%BC%E5%85%A5%E7%9A%84%E6%A8%A1%E5%9D%97/:3:1","tags":["Programming"],"title":"Python 删除已导入的模块","uri":"/posts/python-%E5%88%A0%E9%99%A4%E5%B7%B2%E5%AF%BC%E5%85%A5%E7%9A%84%E6%A8%A1%E5%9D%97/"},{"categories":[],"content":"使用 del 释放 我们知道，已导入的库会索引于 sys.modules 中，所以是不是可以直接删除索引中这个库就可以了呢？ 在 How to de-import a Python module? - Stack Overflow 这篇帖子中，有人就是这样问的，让我们试一下： # file: de_import_with_del.py import gc import sys with open('/proc/self/status') as f: print('init', ''.join(line for line in f if line.startswith('VmRSS')).strip()) import asyncio with open('/proc/self/status') as f: print('imported', ''.join(line for line in f if line.startswith('VmRSS')).strip()) del asyncio del sys.modules['asyncio'] gc.collect() with open('/proc/self/status') as f: print('de-imported', ''.join(line for line in f if line.startswith('VmRSS')).strip()) 执行结果如下： $ python de_import_with_del.py init VmRSS: 9856 kB imported VmRSS: 20092 kB de-imported VmRSS: 20092 kB 可以看到，这样并不能真正释放已导入模块的内存。 不过，这篇帖子下面还贴了另一个邮件[Tutor] How to un-import modules?，上面提到有一种更进阶的方式进行模块释放，其原理是不仅解除了对模块的引用，还解除了其子模块的使用。 这听起来好像很有道理，让我们再试试： # file: de_import_deep_del.py import gc def delete_module(modname, paranoid=None): from sys import modules try: thismod = modules[modname] except KeyError: raise ValueError(modname) these_symbols = dir(thismod) if paranoid: try: paranoid[:] # sequence support except: # noqa: E722 raise ValueError('must supply a finite list for paranoid') else: these_symbols = paranoid[:] del modules[modname] for mod in modules.values(): try: delattr(mod, modname) except AttributeError: pass if paranoid: for symbol in these_symbols: if symbol[:2] == '__': # ignore special symbols continue try: delattr(mod, symbol) except AttributeError: pass with open('/proc/self/status') as f: print('init', ''.join(line for line in f if line.startswith('VmRSS')).strip()) import asyncio # noqa: E402 with open('/proc/self/status') as f: print('imported', ''.join(line for line in f if line.startswith('VmRSS')).strip()) del asyncio delete_module('asyncio') gc.collect() with open('/proc/self/status') as f: print('de-imported', ''.join(line for line in f if line.startswith('VmRSS')).strip()) 执行结果如下： $ python de_import_deep_del.py init VmRSS: 9984 kB imported VmRSS: 20352 kB de-imported VmRSS: 20352 kB 很可惜，还是不行。 ","date":"2025-06-13","objectID":"/posts/python-%E5%88%A0%E9%99%A4%E5%B7%B2%E5%AF%BC%E5%85%A5%E7%9A%84%E6%A8%A1%E5%9D%97/:3:2","tags":["Programming"],"title":"Python 删除已导入的模块","uri":"/posts/python-%E5%88%A0%E9%99%A4%E5%B7%B2%E5%AF%BC%E5%85%A5%E7%9A%84%E6%A8%A1%E5%9D%97/"},{"categories":[],"content":"使用 deimport 库 probml/deimport 库宣称可以释放已导入的库，让我们试试： # file: demo_of_using_deimport.py import gc from deimport.deimport import deimport with open('/proc/self/status') as f: print('init', ''.join(line for line in f if line.startswith('VmRSS')).strip()) import asyncio with open('/proc/self/status') as f: print('imported', ''.join(line for line in f if line.startswith('VmRSS')).strip()) deimport(asyncio) gc.collect() with open('/proc/self/status') as f: print('de-imported', ''.join(line for line in f if line.startswith('VmRSS')).strip()) 执行结果如下： $ python demo_of_using_deimport.py init VmRSS: 15340 kB imported VmRSS: 24044 kB de-imported VmRSS: 24044 kB 很可惜，还是不行。从其源码可以看到，它相比上面我们介绍的 del 方法无非是多删除了 globals() 内的引用。 ","date":"2025-06-13","objectID":"/posts/python-%E5%88%A0%E9%99%A4%E5%B7%B2%E5%AF%BC%E5%85%A5%E7%9A%84%E6%A8%A1%E5%9D%97/:3:3","tags":["Programming"],"title":"Python 删除已导入的模块","uri":"/posts/python-%E5%88%A0%E9%99%A4%E5%B7%B2%E5%AF%BC%E5%85%A5%E7%9A%84%E6%A8%A1%E5%9D%97/"},{"categories":[],"content":"另辟蹊径 回过头来想一下，从运行时中删除一个已导入模块的难点在哪？笔者觉得主要有两点： 导入模块产生了很多变量和字节码，这些对象可能在很多地方都有引用 一般来说，导入一个稍微大点的模块就会不可避免地导入该模块的依赖模块。这会导致我们在导入一个模块的时候实际上导入了多个模块，而我们有不可能去一一识别然后删除 问题 1 倒是还有解决的余地——我们只需要查看 gc 中的相关引用情况，然后一一删除就好。而问题 2 就比较棘手了，我们很难在导入一个模块时去一一分析其依赖模块的导入，依赖模块是否被别的模块依赖……等等。 让我们把思路放宽一下，另辟蹊径地想一下：什么一定要删除模块呢，不引入不就好了？我们知道一个进程 fork 出来的子进程会继承主进程的资源，而子进程结束并不会影响主进程的运行。那是不是可以先创建一个子进程，然后在这个子进程中完成脏活累活，最后销毁该子进程——这样是不是主进程并不用导入模块，而又利用该模块完成了预定任务？让我们试试。 使用 fork+pipe 代码如下： import os import pickle def run_in_other_process(func, *args, **kwargs): \"\"\" Run a function in another process using os.fork and os.pipe. \"\"\" read_fd, write_fd = os.pipe() pid = os.fork() if pid == 0: # Child process os.close(read_fd) try: result = func(*args, **kwargs) with os.fdopen(write_fd, 'wb') as wf: wf.write(pickle.dumps(result)) except Exception as e: with os.fdopen(write_fd, 'wb') as wf: wf.write(pickle.dumps(e)) os._exit(0) else: # Parent process os.close(write_fd) with os.fdopen(read_fd, 'rb') as rf: result = pickle.loads(rf.read()) if isinstance(result, Exception): raise result return result def a_task_using_asyncio(a): with open('/proc/self/status') as f: print('task init', ''.join(line for line in f if line.startswith('VmRSS')).strip()) import asyncio # noqa: F401 with open('/proc/self/status') as f: print('imported', ''.join(line for line in f if line.startswith('VmRSS')).strip()) return a ** a with open('/proc/self/status') as f: print('init', ''.join(line for line in f if line.startswith('VmRSS')).strip()) assert run_in_other_process(a_task_using_asyncio, 3) == 27 with open('/proc/self/status') as f: print('task done', ''.join(line for line in f if line.startswith('VmRSS')).strip()) 运行结果： $ python demo_of_using_fork+pipe.py init VmRSS: 17120 kB task init VmRSS: 11896 kB imported VmRSS: 21624 kB task done VmRSS: 17248 kB 使用 fork+socketpair 代码如下： import os import pickle import socket def run_in_other_process(func, *args, **kwargs): \"\"\" Run a function in another process using os.fork and socket.socketpair. \"\"\" parent_sock, child_sock = socket.socketpair() pid = os.fork() if pid == 0: # Child process parent_sock.close() try: result = func(*args, **kwargs) child_sock.sendall(pickle.dumps(result)) except Exception as e: child_sock.sendall(pickle.dumps(e)) finally: child_sock.close() os._exit(0) else: # Parent process child_sock.close() result = pickle.loads(parent_sock.recv(4096)) parent_sock.close() if isinstance(result, Exception): raise result return result def a_task_using_asyncio(a): with open('/proc/self/status') as f: print('task init', ''.join(line for line in f if line.startswith('VmRSS')).strip()) import asyncio # noqa: F401 with open('/proc/self/status') as f: print('imported', ''.join(line for line in f if line.startswith('VmRSS')).strip()) return a ** a with open('/proc/self/status') as f: print('init', ''.join(line for line in f if line.startswith('VmRSS')).strip()) assert run_in_other_process(a_task_using_asyncio, 3) == 27 with open('/proc/self/status') as f: print('task done', ''.join(line for line in f if line.startswith('VmRSS')).strip()) 运行结果： $ python demo_of_using_fork+socketpair.py init VmRSS: 17492 kB task init VmRSS: 12204 kB imported VmRSS: 21676 kB task done VmRSS: 17620 kB 使用 multiprocessing 代码如下： import multiprocessing def run_in_other_process(func, *args, **kwargs): \"\"\" Run a function in another process. \"\"\" with multiprocessing.Pool(1) as pool: result = pool.apply(func, args, kwargs) return result def a_task_using_asyncio(a): with open('/proc/self/status') as f: print('task init', ''.join(line for line in f if line.startswith('VmRSS')).strip()) import asyncio # noqa: F401 with open('/proc/self/status') as f: print('imported', ''.join(line for line in f if line.startswith('VmRSS')).strip()) return a ** a with open('/proc/self/status') as f: print('init', ''.join(line for line in f if line.startswith('VmRSS')).strip()) assert run_in_other_process(a_task_using_asyncio, 3) == 27 with open('/proc/self/status') as f: print('task done', ''.join(line for line ","date":"2025-06-13","objectID":"/posts/python-%E5%88%A0%E9%99%A4%E5%B7%B2%E5%AF%BC%E5%85%A5%E7%9A%84%E6%A8%A1%E5%9D%97/:3:4","tags":["Programming"],"title":"Python 删除已导入的模块","uri":"/posts/python-%E5%88%A0%E9%99%A4%E5%B7%B2%E5%AF%BC%E5%85%A5%E7%9A%84%E6%A8%A1%E5%9D%97/"},{"categories":[],"content":"总结 从上个章节，我们可以看到各个方法主进程在执行任务的前后内存用量变化非常少（应该是启动子进程以及进程间通信带来的开销），而主要的内存用量都体现在子进程上了——由于子进程在执行完任务之后会释放，所以完全没有关系。 当然，你可能注意到使用有些方法初始化的内存会比较大，这是因为导入用于创建子进程以及进行进程间通信的库也会消耗相当量的内存。你可以根据自己项目中导入了哪些库、任务传递数据的格式和实际的工程情况，决定你使用什么方法实现 run_in_other_process 中关于子进程启动和进程间通信的部分。 ","date":"2025-06-13","objectID":"/posts/python-%E5%88%A0%E9%99%A4%E5%B7%B2%E5%AF%BC%E5%85%A5%E7%9A%84%E6%A8%A1%E5%9D%97/:3:5","tags":["Programming"],"title":"Python 删除已导入的模块","uri":"/posts/python-%E5%88%A0%E9%99%A4%E5%B7%B2%E5%AF%BC%E5%85%A5%E7%9A%84%E6%A8%A1%E5%9D%97/"},{"categories":[],"content":"资源 本文档所有相关文件和脚本均已上传到 Github How to de-import a Python module? - Stack Overflow [Tutor] How to un-import modules? ","date":"2025-06-13","objectID":"/posts/python-%E5%88%A0%E9%99%A4%E5%B7%B2%E5%AF%BC%E5%85%A5%E7%9A%84%E6%A8%A1%E5%9D%97/:4:0","tags":["Programming"],"title":"Python 删除已导入的模块","uri":"/posts/python-%E5%88%A0%E9%99%A4%E5%B7%B2%E5%AF%BC%E5%85%A5%E7%9A%84%E6%A8%A1%E5%9D%97/"},{"categories":null,"content":"概况 本文档描述了使用 django 创建 web 项目，并通过 uWSGI 启动的方法和过程。 ","date":"2025-06-03","objectID":"/posts/uwsgi+django-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/:1:0","tags":null,"title":"uWSGI+Django 最简实践","uri":"/posts/uwsgi+django-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/"},{"categories":null,"content":"启动前准备 ","date":"2025-06-03","objectID":"/posts/uwsgi+django-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/:2:0","tags":null,"title":"uWSGI+Django 最简实践","uri":"/posts/uwsgi+django-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/"},{"categories":null,"content":"准备软件 本文档中涉及的软件有 uwsgi 和 django，均可以通过 pip 安装： pip install uwsgi pip install django ","date":"2025-06-03","objectID":"/posts/uwsgi+django-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/:2:1","tags":null,"title":"uWSGI+Django 最简实践","uri":"/posts/uwsgi+django-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/"},{"categories":null,"content":"准备网站 下面我们通过 django-admin 创建一个最简单的应项目： django-admin startproject mysite 创建好的 django 项目在 mysite 路径下。 ","date":"2025-06-03","objectID":"/posts/uwsgi+django-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/:2:2","tags":null,"title":"uWSGI+Django 最简实践","uri":"/posts/uwsgi+django-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/"},{"categories":null,"content":"使用 uWSGI 启动应用 使用 uWSGI 启动创建好的 django 项目： uwsgi --http :8000 --module mysite.wsgi --chdir mysite --pidfile uwsgi.pid --daemonize uwsgi.log --vacuum 参数说明： 参数 说明 –http :8000 在 8000 端口启动 HTTP 服务器 –module mysite.wsgi 启动的应用 –chdir mysite 应用的路径 –pidfile uwsgi.pid 启动后留下 pid 文件 –daemonize uwsgi.log 启动后在后台运行，日志输出到 uwsgi.log –vacuum 进程结束时自动删除 pid 文件等临时文件 ","date":"2025-06-03","objectID":"/posts/uwsgi+django-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/:3:0","tags":null,"title":"uWSGI+Django 最简实践","uri":"/posts/uwsgi+django-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/"},{"categories":null,"content":"验证 启动后，可以使用浏览器访问 http://localhost:8000 ，可以看到 django 的欢迎页面。 除此之外，也可以使用 curl 命令访问网站： focksor@focksor:~/workSpace/uwsgi_django_demo$ curl -s http://localhost:8000/ | grep \"The install worked successfully! Congratulations!\" \u003ctitle\u003eThe install worked successfully! Congratulations!\u003c/title\u003e \u003ch1\u003eThe install worked successfully! Congratulations!\u003c/h1\u003e focksor@focksor:~/workSpace/uwsgi_django_demo$ ","date":"2025-06-03","objectID":"/posts/uwsgi+django-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/:3:1","tags":null,"title":"uWSGI+Django 最简实践","uri":"/posts/uwsgi+django-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/"},{"categories":null,"content":"终止 在上面我们使用后台运行的方式运行 uwsgi，并留下了 pid 文件。故我们只需要 cat 这个 pid 文件并 kill 掉对应进程就好： kill `cat uwsgi.pid` ","date":"2025-06-03","objectID":"/posts/uwsgi+django-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/:3:2","tags":null,"title":"uWSGI+Django 最简实践","uri":"/posts/uwsgi+django-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/"},{"categories":null,"content":"资源 编写你的第一个 Django 应用，第 1 部分 | Django documentation | Django 如何用 uWSGI 托管 Django | Django documentation | Django 本文相关脚本已上传到 Github：focksor/uwsgi_django_demo ","date":"2025-06-03","objectID":"/posts/uwsgi+django-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/:4:0","tags":null,"title":"uWSGI+Django 最简实践","uri":"/posts/uwsgi+django-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/"},{"categories":null,"content":"概况 uWSGI 提供了一个 cgi 插件，可以让你通过 uWSGI 来运行传统的 CGI 脚本（虽然现在一般不会有人这样做）。 ⚠️ 注意事项 uWSGI 的 CGI 插件性能一般，并不适合高并发或生产环境，只适合兼容旧系统或做一些调试。 它只是提供了一个兼容层，内部仍是 fork+exec 来执行 CGI 脚本，性能开销与传统 CGI 接近。 uWSGI 更多的是用于运行 WSGI 应用，如 Flask、Django，而不是传统 CGI。 ","date":"2025-05-31","objectID":"/posts/uwsgi+cgi-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/:1:0","tags":null,"title":"uWSGI+CGI 最简实践","uri":"/posts/uwsgi+cgi-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/"},{"categories":null,"content":"安装 uWSGI ","date":"2025-05-31","objectID":"/posts/uwsgi+cgi-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/:2:0","tags":null,"title":"uWSGI+CGI 最简实践","uri":"/posts/uwsgi+cgi-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/"},{"categories":null,"content":"编译安装 uWSGI+CGI plugin uWSGI 默认不支持 CGI 应用。要支持 CGI，则需要安装其 CGI plugin。通过以下命令编译 uWSGI 及其 CGI 补丁： git clone git@github.com:unbit/uwsgi.git -b uwsgi-2.0 --depth=1 cd uwsgi make PROFILE=cgi python uwsgiconfig.py --plugin plugins/cgi 编译完成后，通过以下命令验证 uWSGI 的可用性： $ ls ./cgi_plugin.so ./cgi_plugin.so $ ./uwsgi --plugin cgi --plugins-list 2\u003e\u00261 | grep cgi 9: cgi 如上所示，uWSGI 以及其 cgi 插件已经就绪。 ","date":"2025-05-31","objectID":"/posts/uwsgi+cgi-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/:2:1","tags":null,"title":"uWSGI+CGI 最简实践","uri":"/posts/uwsgi+cgi-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/"},{"categories":null,"content":"编写 CGI 应用 CGI 应用说白了就是一个可执行的程序，启动后能够输出 HTTP 响应内容就好了。下面是使用 C 和 BASH 实现的 CGI 应用。 ","date":"2025-05-31","objectID":"/posts/uwsgi+cgi-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/:3:0","tags":null,"title":"uWSGI+CGI 最简实践","uri":"/posts/uwsgi+cgi-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/"},{"categories":null,"content":"使用 C 创建 CGI 应用 创建 hello.c： #include \u003cstdio.h\u003e int main(void) { printf(\"Content-type: text/plain\\n\\n\"); printf(\"Hello, CGI world!\\n\"); return 0; } 将其编译为 cgi 应用，编译后尝试执行，可以输出内容： $ gcc hello.c -o apps/hello.cgi $ ./apps/hello.cgi Content-type: text/plain Hello, CGI world! ","date":"2025-05-31","objectID":"/posts/uwsgi+cgi-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/:3:1","tags":null,"title":"uWSGI+CGI 最简实践","uri":"/posts/uwsgi+cgi-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/"},{"categories":null,"content":"使用 Bash 创建 CGI 应用 编写 bash.cgi #!/bin/bash echo \"Content-Type: text/plain\" echo \"\" echo \"Hello, CGI Bash Script!\" 创建后给它赋予执行权限，并尝试执行，可以输出内容： $ chmod +x apps/bash.cgi $ ./apps/bash.cgi Content-Type: text/plain Hello, CGI Bash Script! ","date":"2025-05-31","objectID":"/posts/uwsgi+cgi-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/:3:2","tags":null,"title":"uWSGI+CGI 最简实践","uri":"/posts/uwsgi+cgi-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/"},{"categories":null,"content":"启动 uWSGI 通过以下命令启动 uWSGI 应用： ./uwsgi --plugin cgi --cgi ../uwsgi_simple_app/apps/ --http-socket :9000 --http-socket-modifier1 9 参数说明： 参数 说明 –plugin cgi 加载 cgi plugin –cgi ../uwsgi_simple_app/apps/ 指定 cgi 应用所在的路径 –http-socket :9000 使用 HTTP 协议，绑定到 9000 端口 –http-socket-modifier1 9 使用 CGI 补丁处理 HTTP 协议的请求。其中 9 是 CGI 的标识，可以用如下命令看到：./uwsgi --plugin cgi --plugins-list 2\u003e\u00261 | grep cgi ","date":"2025-05-31","objectID":"/posts/uwsgi+cgi-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/:4:0","tags":null,"title":"uWSGI+CGI 最简实践","uri":"/posts/uwsgi+cgi-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/"},{"categories":null,"content":"验证访问 uWSGI 启动后，可以通过 curl 或浏览器访问相应的 url 以访问应用。下面以 curl 为例： $ curl http://localhost:9000/hello.cgi Hello, CGI world! $ curl http://localhost:9000/bash.cgi Hello, CGI Bash Script! ","date":"2025-05-31","objectID":"/posts/uwsgi+cgi-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/:4:1","tags":null,"title":"uWSGI+CGI 最简实践","uri":"/posts/uwsgi+cgi-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/"},{"categories":null,"content":"易踩坑问题 未加载应用 如果启动日志中输出以下内容： *** no app loaded. GAME OVER *** 这是因为 CGI 应用是动态加载的，所以会显示没有加载应用，上面的日志是正常的。 但是如果启动日志中输出以下内容 *** no app loaded. GAME OVER *** 则需要在启动参数中加入 --need-app=false (或删除 --need-app=true，如果你加了的话)。 ","date":"2025-05-31","objectID":"/posts/uwsgi+cgi-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/:5:0","tags":null,"title":"uWSGI+CGI 最简实践","uri":"/posts/uwsgi+cgi-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/"},{"categories":null,"content":"未找到标识符 0 出现该问题时，启动日志中输出以下内容： -- unavailable modifier requested: 0 -- 且 curl 或浏览器无法访问 uwsgi 绑定的服务器地址。这是因为 uwsgi 默认是以 Python 插件（标识符为 0）处理的，如果你的 uWSGI 并没有编译这个插件，则会报这个错误。 解决方法： 在我们的应用场景中（使用 CGI 插件处理 HTTP 请求），是完全不用 Python 插件的。因此，当出现该问题的时候，你只需要在启动命令加上参数 --http-socket-modifier1 9，要求 uWSGI 以 CGI 插件（标识符为 9）处理 http-socket 请求就好了。 如果你不是通过 --http-socket 参数的方式绑定监听地址，则使用 ./uwsgi --help | grep modifier1 查看并找到符合你需求的参数。 但是，如果你确实是想要以 Python 插件启动应用时遇到了这个问题，则是因为你的 uWSGI 并没有集成 Python 插件，使用以下命令重新编译 uWSGI 以解决问题： make clean make PROFILE=default ","date":"2025-05-31","objectID":"/posts/uwsgi+cgi-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/:5:1","tags":null,"title":"uWSGI+CGI 最简实践","uri":"/posts/uwsgi+cgi-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/"},{"categories":null,"content":"未找到 Python 应用 出现该问题时，启动日志中输出以下内容： --- no python application found, check your startup logs for errors --- 这种情况是因为你的 uWSGI 中已经集成了 Python 插件，当 uWSGI 启动时会默认去查找是否有 Python web 应用（很明显在我们这篇文档所述的环境里是找不到的），因此会提示此错误。 这个问题出现的原因其实跟上个问题是一样的，错误信息仅仅取决于你的 uWSG 是否集成了 Python 插件。要解决这个问题，我们需要添加一个参数来切换默认的处理应用：--http-socket-modifier1 9（同上个问题的解决方法）。 ","date":"2025-05-31","objectID":"/posts/uwsgi+cgi-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/:5:2","tags":null,"title":"uWSGI+CGI 最简实践","uri":"/posts/uwsgi+cgi-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/"},{"categories":null,"content":"找不到 CGI 插件 出现该问题时，启动日志中输出以下内容： open(\"./cgi_plugin.so\"): No such file or directory [core/utils.c line 3709] !!! UNABLE to load uWSGI plugin: ./cgi_plugin.so: cannot open shared object file: No such file or directory !!! 这是因为你没有编译 CGI 插件。使用以下命令编译插件以解决问题： python uwsgiconfig.py --plugin plugins/cgi ","date":"2025-05-31","objectID":"/posts/uwsgi+cgi-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/:5:3","tags":null,"title":"uWSGI+CGI 最简实践","uri":"/posts/uwsgi+cgi-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/"},{"categories":null,"content":"资源 上文中所有提及的源码及其验证脚本打包上传到了 Github 上，希望对你有帮助。 uWSGI CGI 官方文档：Running CGI scripts on uWSGI — uWSGI 2.0 documentation ","date":"2025-05-31","objectID":"/posts/uwsgi+cgi-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/:6:0","tags":null,"title":"uWSGI+CGI 最简实践","uri":"/posts/uwsgi+cgi-%E6%9C%80%E7%AE%80%E5%AE%9E%E8%B7%B5/"},{"categories":null,"content":"Hello World! Here is my first post. ","date":"2025-03-31","objectID":"/posts/hello_world/:0:1","tags":null,"title":"Hello World!","uri":"/posts/hello_world/"}]